# -*- coding: utf-8 -*-
"""Google Zero Day in the Wild.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15hGdVFJabA8TVNLiJ4b7spP8-dwvu9PY

Imports
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
from tensorflow import keras
from keras.callbacks import EarlyStopping, ReduceLROnPlateau

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files

uploaded = files.upload()

df = pd.read_csv((list(uploaded.keys())[0] ))

df.head()

"""Top 10 most Zero-Day according to Companies."""

values = df['Type'].value_counts()
plt.figure(figsize=(12, 6))
plt.bar(values[:10].index, values[:10])
plt.xlabel('Type')
plt.ylabel('Number of Exploits')
plt.xticks(rotation=45)
plt.title('Top 10 Zero-Day Exploit Types')
plt.show()

"""The types of Zero-Day Exploitation."""

df['Type'].value_counts()

"""Classification based on the Exploitation type.

"""

df['Date Discovered'].fillna('Unknown', inplace=True)
df['Root Cause Analysis'].fillna('Unknown', inplace=True)
df['Analysis URL'].fillna('Unknown', inplace=True)
df['Type'].fillna('Unknown', inplace=True)

le = LabelEncoder()
for column in ['CVE', 'Type', 'Vendor', 'Product', 'Description', 'Date Patched', 'Advisory']:
    df[column] = le.fit_transform(df[column])

X = df[['CVE', 'Vendor', 'Product', 'Description', 'Date Discovered',
       'Date Patched', 'Advisory', 'Analysis URL', 'Root Cause Analysis']]
y = df['Type']

for column in ['Date Discovered','Analysis URL', 'Root Cause Analysis']:
  X[column] = le.fit_transform(X[column])

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)
df['Type']

from google.colab import drive
drive.mount('/content/drive')

"""Building the Model"""

model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(len(y.unique()), activation='softmax')
])

"""Compiling the Model."""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)

"""Training the model"""

model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2)
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy}')

"""Making predictions"""

predictions = model.predict(X_test)
predicted_classes = tf.argmax(predictions, axis=1)

predicted_classes

"""Confusion Matrix"""

conf_matrix = confusion_matrix(y_test, predicted_classes)
print(f'Confusion Matrix:\n{conf_matrix}')

accuracy = accuracy_score(y_test, predicted_classes)
print(f'Accuracy: {accuracy}')

# Classification Report
class_report = classification_report(y_test, predicted_classes)
print(f'Classification Report:\n{class_report}')

"""Plotting the Confusion Matrix"""

plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()